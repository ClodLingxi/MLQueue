"""
MLQueue V2 + PyTorch é›†æˆç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨V2 APIæ§åˆ¶PyTorchè®­ç»ƒæµç¨‹
"""
from mlqueue import MLQueueV2Client, QueueStatus
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset


# å®šä¹‰ç®€å•çš„ç¥ç»ç½‘ç»œ
class SimpleNN(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        return x


def create_dummy_dataset(n_samples=1000, input_size=20, output_size=2):
    """åˆ›å»ºè™šæ‹Ÿæ•°æ®é›†ç”¨äºæ¼”ç¤º"""
    X = torch.randn(n_samples, input_size)
    y = torch.randint(0, output_size, (n_samples,))
    return TensorDataset(X, y)


def train_with_parameters(parameters):
    """
    ä½¿ç”¨ç»™å®šå‚æ•°è®­ç»ƒPyTorchæ¨¡å‹

    Args:
        parameters: è®­ç»ƒå‚æ•°å­—å…¸ï¼ŒåŒ…å«:
            - hidden_size: éšè—å±‚å¤§å°
            - learning_rate: å­¦ä¹ ç‡
            - batch_size: æ‰¹æ¬¡å¤§å°
            - epochs: è®­ç»ƒè½®æ•°

    Returns:
        è®­ç»ƒç»“æœå­—å…¸
    """
    # æå–å‚æ•°
    hidden_size = parameters.get("hidden_size", 64)
    learning_rate = parameters.get("learning_rate", 0.001)
    batch_size = parameters.get("batch_size", 32)
    epochs = parameters.get("epochs", 5)
    input_size = parameters.get("input_size", 20)
    output_size = parameters.get("output_size", 2)

    print(f"\n{'='*70}")
    print(f"è®­ç»ƒé…ç½®:")
    print(f"  Hidden Size: {hidden_size}")
    print(f"  Learning Rate: {learning_rate}")
    print(f"  Batch Size: {batch_size}")
    print(f"  Epochs: {epochs}")
    print(f"{'='*70}\n")

    # åˆ›å»ºæ•°æ®é›†
    dataset = create_dummy_dataset(n_samples=1000, input_size=input_size, output_size=output_size)
    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # åˆ›å»ºæ¨¡å‹
    model = SimpleNN(input_size=input_size, hidden_size=hidden_size, output_size=output_size)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)

    # è®­ç»ƒå¾ªç¯
    best_loss = float('inf')
    epoch_losses = []
    epoch_accuracies = []

    for epoch in range(epochs):
        model.train()
        epoch_loss = 0.0
        correct = 0
        total = 0

        for batch_idx, (data, target) in enumerate(train_loader):
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()

            epoch_loss += loss.item()

            # è®¡ç®—å‡†ç¡®ç‡
            _, predicted = torch.max(output.data, 1)
            total += target.size(0)
            correct += (predicted == target).sum().item()

        # è®¡ç®—å¹³å‡æŸå¤±å’Œå‡†ç¡®ç‡
        avg_loss = epoch_loss / len(train_loader)
        accuracy = 100 * correct / total

        epoch_losses.append(avg_loss)
        epoch_accuracies.append(accuracy)

        if avg_loss < best_loss:
            best_loss = avg_loss

        print(f"Epoch [{epoch + 1}/{epochs}] - Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%")

    # å‡†å¤‡è¿”å›ç»“æœ
    result = {
        "best_loss": best_loss,
        "final_loss": epoch_losses[-1],
        "final_accuracy": epoch_accuracies[-1],
        "epoch_losses": epoch_losses,
        "epoch_accuracies": epoch_accuracies
    }

    print(f"\nè®­ç»ƒå®Œæˆ!")
    print(f"  æœ€ä½³Loss: {best_loss:.4f}")
    print(f"  æœ€ç»ˆå‡†ç¡®ç‡: {epoch_accuracies[-1]:.2f}%")
    print(f"{'='*70}\n")

    return result


def main():
    print("="*70)
    print("MLQueue V2 + PyTorch é›†æˆç¤ºä¾‹")
    print("="*70)

    # 1. è¿æ¥åˆ°MLQueue V2
    print("\n[1] è¿æ¥åˆ°MLQueue V2...")
    client = MLQueueV2Client(
        api_url="http://localhost:8080/v2",
        api_key="demo-api-key-12345"
    )
    print("âœ“ è¿æ¥æˆåŠŸ\n")

    # 2. åˆ›å»ºé¡¹ç›®ç»„
    print("[2] åˆ›å»ºé¡¹ç›®ç»„...")
    group = client.create_group(
        name="PyTorchè¶…å‚æ•°æœç´¢",
        description="ç¥ç»ç½‘ç»œè¶…å‚æ•°ä¼˜åŒ–å®éªŒ"
    )
    print(f"âœ“ ç»„åˆ›å»ºæˆåŠŸ: {group.name}\n")

    # 3. åˆ›å»ºè®­ç»ƒå•å…ƒ
    print("[3] åˆ›å»ºè®­ç»ƒå•å…ƒ...")
    unit = group.create_training_unit(
        name="éšè—å±‚å¤§å° vs å­¦ä¹ ç‡",
        config={
            "model": "SimpleNN",
            "dataset": "synthetic",
            "optimizer": "Adam"
        },
        description="æµ‹è¯•ä¸åŒéšè—å±‚å¤§å°å’Œå­¦ä¹ ç‡çš„ç»„åˆ"
    )
    print(f"âœ“ è®­ç»ƒå•å…ƒåˆ›å»ºæˆåŠŸ: {unit.name}\n")

    # 4. æ‰¹é‡æ·»åŠ è®­ç»ƒé˜Ÿåˆ—
    print("[4] æ‰¹é‡æ·»åŠ è®­ç»ƒé˜Ÿåˆ—...")

    # å®šä¹‰è¶…å‚æ•°ç½‘æ ¼
    hidden_sizes = [32, 64, 128]
    learning_rates = [0.001, 0.01]

    queue_configs = []
    for hs in hidden_sizes:
        for lr in learning_rates:
            queue_configs.append({
                "name": f"hs{hs}_lr{lr}",
                "parameters": {
                    "hidden_size": hs,
                    "learning_rate": lr,
                    "batch_size": 32,
                    "epochs": 3,
                    "input_size": 20,
                    "output_size": 2
                },
                "created_by": "client"
            })

    queues = unit.add_queues_batch(queue_configs)
    print(f"âœ“ æ‰¹é‡åˆ›å»ºäº† {len(queues)} ä¸ªè®­ç»ƒé˜Ÿåˆ—")
    for q in queues:
        print(f"  - {q.name}")
    print()

    # 5. ä¸»åŠ¨åŒæ­¥
    print("[5] ä»äº‘ç«¯åŒæ­¥...")
    sync_result = unit.sync()
    print(f"  ç‰ˆæœ¬: {unit.version}")
    print(f"  å¾…æ‰§è¡Œé˜Ÿåˆ—æ•°: {len(unit.get_pending_queues())}\n")

    # 6. æ‰§è¡Œè®­ç»ƒå¾ªç¯
    print("[6] å¼€å§‹æ‰§è¡Œè®­ç»ƒå¾ªç¯...")
    print("-"*70)

    pending_queues = unit.get_pending_queues()
    total = len(pending_queues)

    for i, queue in enumerate(pending_queues, 1):
        print(f"\n>>> é˜Ÿåˆ— [{i}/{total}]: {queue.name}")

        # å¼€å§‹æ‰§è¡Œ
        queue.start()

        try:
            # æ‰§è¡ŒPyTorchè®­ç»ƒ
            result = train_with_parameters(queue.parameters)

            # æ ‡è®°å®Œæˆ
            queue.complete(
                result=result,
                metrics={
                    "best_loss": result["best_loss"],
                    "final_accuracy": result["final_accuracy"]
                }
            )
            print(f"âœ“ é˜Ÿåˆ—å®Œæˆ: {queue.name}")

        except Exception as e:
            # æ ‡è®°å¤±è´¥
            import traceback
            error_msg = f"{str(e)}\n{traceback.format_exc()}"
            queue.fail(error_msg)
            print(f"âœ— é˜Ÿåˆ—å¤±è´¥: {queue.name}")
            print(f"é”™è¯¯: {e}")

        print("-"*70)

    # 7. åˆ†æç»“æœ
    print("\n[7] åˆ†æè®­ç»ƒç»“æœ...")
    completed_queues = unit.list_queues(status=QueueStatus.COMPLETED)

    print(f"\nå·²å®Œæˆé˜Ÿåˆ—æ•°: {len(completed_queues)}\n")
    print(f"{'é˜Ÿåˆ—åç§°':<20} {'æœ€ä½³Loss':<12} {'æœ€ç»ˆå‡†ç¡®ç‡':<12}")
    print("-"*70)

    best_result = None
    best_accuracy = 0

    for q in completed_queues:
        if q.metrics:
            accuracy = q.metrics.get('final_accuracy', 0)
            loss = q.metrics.get('best_loss', 0)
            print(f"{q.name:<20} {loss:<12.4f} {accuracy:<12.2f}%")

            if accuracy > best_accuracy:
                best_accuracy = accuracy
                best_result = {
                    "name": q.name,
                    "parameters": q.parameters,
                    "accuracy": accuracy,
                    "loss": loss
                }

    # 8. æ˜¾ç¤ºæœ€ä½³ç»“æœ
    if best_result:
        print(f"\n{'='*70}")
        print("ğŸ† æœ€ä½³ç»“æœ:")
        print(f"  é˜Ÿåˆ—: {best_result['name']}")
        print(f"  å‡†ç¡®ç‡: {best_result['accuracy']:.2f}%")
        print(f"  æŸå¤±: {best_result['loss']:.4f}")
        print(f"  å‚æ•°:")
        for key, value in best_result['parameters'].items():
            print(f"    {key}: {value}")
        print(f"{'='*70}")

    print("\nâœ“ æ‰€æœ‰è®­ç»ƒå®Œæˆ!")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\næ“ä½œå·²å–æ¶ˆ")
    except Exception as e:
        print(f"\n\né”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
